# eliminamos los "-", para obtener la fecha sin guiones
fecha_yesterday <- gsub("-", "",fecha_yesterday); fecha_yesterday
# la siguiente url contiene el archivo CSV del 10 de octubre de 2021
# con la información correspondiente , la cual va a ser modificada
url_covid <- 'https://datos.covid-19.conacyt.mx/Downloads/Files/Casos_Diarios_Municipio_Defunciones_20211010.csv'
# igualemnte con la función gsub, reemplazamos ahora
# en la url los ultimos valores por la fecha actuañ
url_covid <- gsub("20211010", fecha_yesterday, url_covid); url_covid
data <- read.csv(url_covid, header = TRUE)
if (any(is.na(data)) == TRUE) {data = tidyr::drop_na(data)}  # TRUE = hay al menos un valor NA
# datos con información de destinos turisticos
# ahora leemos los datos que vamos a cruzar
NCLugares <- 'C:/Users/David/OneDrive/Documentos/DAOS curses/Datalab SDC4/demo 1/liquibase-covid/code daos/Destinos_mexico.csv'
data2 <- read.csv(NCLugares, header = TRUE)
if (any(is.na(data2)) == TRUE) {data2 = tidyr::drop_na(data2)}  # TRUE = hay al menos un valor NA
# leemos la base de defunciones para obtener solamente a la ciudad de mexico
url_covid2 <- 'https://datos.covid-19.conacyt.mx/Downloads/Files/Casos_Diarios_Estado_Nacional_Defunciones_20211006.csv'
url_covid2 <- gsub("20211006", fecha_yesterday, url_covid2); url_covid2
data3 <- read.csv(url_covid2, header = TRUE)
data4 <- data %>% inner_join(dplyr::select(data2, "cve_ent"), by = "cve_ent")
df <- data4 %>%
rbind(data3 %>% filter(nombre == "DISTRITO FEDERAL"))
df <- df %>%
select(-cve_ent, -poblacion) %>%
pivot_longer(!nombre, names_to = "fecha", values_to = "confirmados") %>%
pivot_wider(names_from = nombre, values_from = confirmados) %>%
mutate(fecha = gsub("X", "", fecha)) %>%
mutate(fecha = as.Date(fecha, "%d.%m.%Y")) %>%
select("Ciudad de Mexico" = "DISTRITO FEDERAL", "Acapulco" = "Acapulco de Juarez",
"Campeche" = "Campeche", "Cancun" = "Benito Juarez", "Chichen Itza" = "Tinum",
"Chihuahua" = "Chihuahua", "Cozumel" = "Cozumel", "Cuernavaca" = "Cuernavaca",
"Guadalajara" = "Guadalajara", "Hermosillo" = "Hermosillo", "Isla Mujeres" = "Isla Mujeres",
"Ixtapa Zihuatanejo" = "Zihuatanejo de Azueta", "La Paz" = "La Paz", "Los Cabos" = "Los Cabos",
"Merida" = "Merida", "Monterrey" = "Monterrey", "Morelia" = "Morelia",
"Nuevo Vallarta" = "Bahia de Banderas", "Oaxaca de Juarez" = "Oaxaca de Juarez",
"Playa del Carmen" = "Solidaridad", "Puebla" = "Puebla", "Puerto Vallarta" = "Puerto Vallarta",
"Queretaro" = "Queretaro", "San Luis Potosi" = "San Luis Potosi",
"San Miguel de Allende" = "San Miguel de Allende", "Taxco" =  "Taxco de Alarcon",
"Tequila" = "Tequila", "Tlaxcala" = "Tlaxcala", "Tuxtla Gutierrez" = "Tuxtla Gutierrez",
"Villahermosa" = "Centro", "Zacatecas" = "Zacatecas", "fecha")
if (any(is.na(df)) == TRUE) {df = tidyr::drop_na(df)}  # TRUE = hay al menos un valor NA
# correrlo una vez para guardarlo, despues comentar la función
write.csv(df,
file = 'C:/Users/David/OneDrive/Documentos/DAOS curses/Datalab SDC4/demo 1/liquibase-covid/code daos/defunciones mun.csv',
row.names = F)
acapulco <- ts(df[2],
start = c(2020, as.numeric(format(df$fecha[1], "%j"))),
frequency = 365)
plot(acapulco)
# 'https://datos.covid-19.conacyt.mx/Downloads/Files/Casos_Diarios_Estado_Nacional_Confirmados_20211009.csv'
# 'https://datos.covid-19.conacyt.mx/Downloads/Files/Casos_Diarios_Estado_Nacional_Confirmados_20211006.csv'
#------------- añadir fecha actual automaticamente
# obtenemos la fecha del dia anterior
fecha_yesterday <- Sys.Date()-1; fecha_yesterday
# 'https://datos.covid-19.conacyt.mx/Downloads/Files/Casos_Diarios_Estado_Nacional_Confirmados_20211009.csv'
# 'https://datos.covid-19.conacyt.mx/Downloads/Files/Casos_Diarios_Estado_Nacional_Confirmados_20211006.csv'
#------------- añadir fecha actual automaticamente
# obtenemos la fecha del dia anterior
fecha_yesterday <- Sys.Date()-1; fecha_yesterday
# convertimos ese objeto a uno de tipo "character"
fecha_yesterday <- as.character(fecha_yesterday); fecha_yesterday
# eliminamos los "-", para obtener la fecha corrida
fecha_yesterday <- gsub("-", "",fecha_yesterday); fecha_yesterday
# la siguiente url contiene el archivo CSV del 06 de octubre de 2021
# con la información correspondiente , la cual va a ser modificada
url_covid <- 'https://datos.covid-19.conacyt.mx/Downloads/Files/Casos_Diarios_Estado_Nacional_Confirmados_20211006.csv'
# igualemnte con la función gsub, reemplazamos ahora
# en la url los ultimos valores por la fecha actuañ
url_covid <- gsub("20211006", fecha_yesterday, url_covid); url_covid
data <- read.csv(url_covid, header = TRUE)
library(tidyverse)  #install.packages("tidyverse")
# igualemnte con la función gsub, reemplazamos ahora
# en la url los ultimos valores por la fecha actuañ
url_covid <- gsub("20211006", fecha_yesterday, url_covid); url_covid
data <- read.csv(url_covid, header = TRUE)
library(tidymodels) #install.packages("tidymodels")
library(modeltime)  #install.packages("modeltime")
library(timetk)     #install.packages("timetk")
library(lubridate)  #install.packages("lubridate")
library(tidyverse)  #install.packages("tidyverse")
library(lubridate)  #install.packages("lubridate")
data <- read.csv("C:/Users/David/OneDrive/Documentos/DAOS curses/Datalab SDC4/demo 1/liquibase-covid/code daos/confirmados.csv", header = TRUE)
data <- data %>%
mutate(fecha = as.Date(fecha))
ts.agu <- ts(data[2],
start = c(2020, as.numeric(format(data$fecha[1], "%j"))),
frequency = 365)
ts.agu.tbl <- data %>%
select(1, 2) %>%  # select(fecha, AGUASCALIENTES)
set_names(c("date", "confirmados"))
head(ts.agu.tbl)
ts.agu.tbl %>%
plot_time_series(date, confirmados, .interactive = F)
splits <- ts.agu.tbl %>%
time_series_split(assess = "3 months", cumulative = TRUE)
splits %>%
tk_time_series_cv_plan() %>%
plot_time_series_cv_plan(date, confirmados, .interactive = FALSE)
model_fit_arima <- arima_reg() %>%
set_engine("auto_arima") %>%
fit(confirmados ~ date, training(splits))
model_fit_arima
model_fit_prophet <- prophet_reg(seasonality_daily = TRUE) %>%
set_engine("prophet") %>%
fit(confirmados ~ date, training(splits))
model_fit_prophet
recipe_spec <- recipe(confirmados ~ date, training(splits)) %>%
step_timeseries_signature(date) %>%
step_rm(contains("am.pm"), contains("hour"), contains("minute"),
contains("second"), contains("xts")) %>%
step_fourier(date, period = 365, K = 5) %>%
step_dummy(all_nominal())
recipe_spec %>% prep() %>% juice()
model_spec_glmnet <- linear_reg(penalty = 0.01, mixture = 0.5) %>%
set_engine("glmnet")
workflow_fit_glmnet <- workflow() %>%
add_model(model_spec_glmnet) %>%
add_recipe(recipe_spec %>% step_rm(date)) %>%
fit(training(splits))
model_spec_rf <- rand_forest(trees = 500, min_n = 50) %>%
set_engine("randomForest")
workflow_fit_rf <- workflow() %>%
add_model(model_spec_rf) %>%
add_recipe(recipe_spec %>% step_rm(date)) %>%
fit(training(splits))
model_spec_prophet_boost <- prophet_boost(seasonality_yearly = TRUE) %>%
set_engine("prophet_xgboost")
workflow_fit_prophet_boost <- workflow() %>%
add_model(model_spec_prophet_boost) %>%
add_recipe(recipe_spec) %>%
fit(training(splits))
workflow_fit_prophet_boost
model_fit_nnetar <- nnetar_reg() %>%
set_engine("nnetar") %>%
fit(confirmados ~ date, training(splits))
model_fit_nnetar
model_table <- modeltime_table(
model_fit_arima,
model_fit_prophet,
workflow_fit_glmnet,
workflow_fit_rf,
workflow_fit_prophet_boost,
model_fit_nnetar
)
model_table
calibration_table <- model_table %>%
modeltime_calibrate(testing(splits))
calibration_table
calibration_table %>%
modeltime_forecast(actual_data = ts.agu.tbl) %>%
plot_modeltime_forecast(.interactive = T)
calibration_table %>%
modeltime_accuracy() %>%
table_modeltime_accuracy(.interactive = F)
library(tidyverse) #install.packages("tidyverse")
# 'https://datos.covid-19.conacyt.mx/Downloads/Files/Casos_Diarios_Estado_Nacional_Confirmados_20211009.csv'
# 'https://datos.covid-19.conacyt.mx/Downloads/Files/Casos_Diarios_Estado_Nacional_Confirmados_20211006.csv'
#------------- añadir fecha actual automaticamente
# obtenemos la fecha del dia anterior
fecha_yesterday <- Sys.Date()-1; fecha_yesterday
# convertimos ese objeto a uno de tipo "character"
fecha_yesterday <- as.character(fecha_yesterday); fecha_yesterday
# eliminamos los "-", para obtener la fecha corrida
fecha_yesterday <- gsub("-", "",fecha_yesterday); fecha_yesterday
# la siguiente url contiene el archivo CSV del 06 de octubre de 2021
# con la información correspondiente , la cual va a ser modificada
url_covid <- 'https://datos.covid-19.conacyt.mx/Downloads/Files/Casos_Diarios_Estado_Nacional_Defunciones_20211006.csv'
# igualemnte con la función gsub, reemplazamos ahora
# en la url los ultimos valores por la fecha actuañ
url_covid <- gsub("20211006", fecha_yesterday, url_covid); url_covid
data <- read.csv(url_covid, header = TRUE)
data <- data %>%
select(-cve_ent, -poblacion) %>%
pivot_longer(!nombre, names_to = "fecha", values_to = "defunciones") %>%
pivot_wider(names_from = nombre, values_from = defunciones) %>%
mutate(fecha = gsub("X", "", fecha)) %>%
mutate(fecha = as.Date(fecha, "%d.%m.%Y")) %>%
select(c(2:33),1)
if (any(is.na(data)) == TRUE) {data = tidyr::drop_na(data)}  # TRUE = hay al menos un valor NA
library(tidymodels) #install.packages("tidymodels")
library(modeltime)  #install.packages("modeltime")
library(timetk)     #install.packages("timetk")
library(lubridate)  #install.packages("lubridate")
library(tidyverse)  #install.packages("tidyverse")
library(lubridate)  #install.packages("lubridate")
ts.agu <- ts(data[2],
start = c(2020, as.numeric(format(data$fecha[1], "%j"))),
frequency = 365)
ts.agu <- ts(data[2],
start = c(2020, as.numeric(format(data$fecha[1], "%j"))),
frequency = 365)
ts.agu.tbl <- data %>%
select(33, 1) %>%  # select(fecha, AGUASCALIENTES)
set_names(c("date", "confirmados"))
head(ts.agu.tbl)
ts.agu <- ts(data[1],
start = c(2020, as.numeric(format(data$fecha[1], "%j"))),
frequency = 365)
ts.agu.tbl <- data %>%
select(33, 1) %>%  # select(fecha, AGUASCALIENTES)
set_names(c("date", "confirmados"))
head(ts.agu.tbl)
ts.agu.tbl %>%
plot_time_series(date, confirmados, .interactive = F)
splits <- ts.agu.tbl %>%
time_series_split(assess = "3 months", cumulative = TRUE)
ts.agu.tbl %>%
plot_time_series(date, confirmados, .interactive = F)
splits <- ts.agu.tbl %>%
time_series_split(assess = "3 months", cumulative = TRUE)
splits %>%
tk_time_series_cv_plan() %>%
plot_time_series_cv_plan(date, confirmados, .interactive = FALSE)
model_fit_arima <- arima_reg() %>%
set_engine("auto_arima") %>%
fit(confirmados ~ date, training(splits))
model_fit_arima
model_fit_prophet <- prophet_reg(seasonality_daily = TRUE) %>%
set_engine("prophet") %>%
fit(confirmados ~ date, training(splits))
model_fit_prophet
recipe_spec <- recipe(confirmados ~ date, training(splits)) %>%
step_timeseries_signature(date) %>%
step_rm(contains("am.pm"), contains("hour"), contains("minute"),
contains("second"), contains("xts")) %>%
step_fourier(date, period = 365, K = 5) %>%
step_dummy(all_nominal())
recipe_spec %>% prep() %>% juice()
model_spec_glmnet <- linear_reg(penalty = 0.01, mixture = 0.5) %>%
set_engine("glmnet")
workflow_fit_glmnet <- workflow() %>%
add_model(model_spec_glmnet) %>%
add_recipe(recipe_spec %>% step_rm(date)) %>%
fit(training(splits))
model_spec_rf <- rand_forest(trees = 500, min_n = 50) %>%
set_engine("randomForest")
workflow_fit_rf <- workflow() %>%
add_model(model_spec_rf) %>%
add_recipe(recipe_spec %>% step_rm(date)) %>%
fit(training(splits))
model_spec_prophet_boost <- prophet_boost(seasonality_yearly = TRUE) %>%
set_engine("prophet_xgboost")
workflow_fit_prophet_boost <- workflow() %>%
add_model(model_spec_prophet_boost) %>%
add_recipe(recipe_spec) %>%
fit(training(splits))
workflow_fit_prophet_boost
model_fit_nnetar <- nnetar_reg() %>%
set_engine("nnetar") %>%
fit(confirmados ~ date, training(splits))
model_fit_nnetar
model_table <- modeltime_table(
model_fit_arima,
model_fit_prophet,
workflow_fit_glmnet,
workflow_fit_rf,
workflow_fit_prophet_boost,
model_fit_nnetar
)
model_table
calibration_table <- model_table %>%
modeltime_calibrate(testing(splits))
calibration_table
calibration_table %>%
modeltime_forecast(actual_data = ts.agu.tbl) %>%
plot_modeltime_forecast(.interactive = T)
calibration_table %>%
modeltime_accuracy() %>%
table_modeltime_accuracy(.interactive = F)
calibration_table %>%
conf_mat(truth = ts.agu.tbl)
calibration_table %>%
modeltime_accuracy(acc_by_id = TRUE) %>%
table_modeltime_accuracy(.interactive = F)
calibration_table %>%
modeltime_accuracy(acc_by_id = F) %>%
table_modeltime_accuracy(.interactive = F)
calibration_table <- model_table %>%
modeltime_calibrate(testing(splits), acc_by_id=TRUE)
calibration_table %>%
modeltime_accuracy() %>%
table_modeltime_accuracy(.interactive = F)
calibration_table <- model_table %>%
modeltime_calibrate(testing(splits), acc_by_id=TRUE)
calibration_table
calibration_table
modeltime_accuracy(calibration_table,, acc_by_id=TRUE )
modeltime_accuracy(calibration_table, acc_by_id=TRUE )
model_table
model_table
model_table %>%
modeltime_calibrate(testing(splits))
model_table %>%
modeltime_calibrate(testing(splits), id = TRUE)
rlang::last_error()
testing(splits)
model_table
modeltime::modeltime_calibrate(model_table, testing(splits), id = TRUE)
modeltime::modeltime_calibrate(model_table, testing(splits))
modeltime::modeltime_calibrate(model_table, testing(splits), id = 'demo')
modeltime::modeltime_calibrate(model_table, testing(splits), id = NULL)
model_table
modeltime::modeltime_calibrate(model_table, testing(splits), id = '.model_id')
testing(splits)
model_table
modeltime_accuracy(calibration_table, quiet = F)
modeltime_accuracy(calibration_table, quiet = T)
modeltime_accuracy(calibration_table,  metric_set(accuracy))
calibration_table
modeltime_accuracy(calibration_table,  metric_set(mae))
modeltime_accuracy(calibration_table,  metric_set(mae), quiet = False)
modeltime_accuracy(calibration_table)
model_table %>%
modeltime_calibrate(testing(splits)) %>%
modeltime_accuracy()
model_table %>%
modeltime_calibrate(testing(splits)) %>%
modeltime_accuracy( metric_set = metric_set(mae, rmse, rsq))
model_table %>%
modeltime_calibrate(testing(splits)) %>%
modeltime_accuracy( metric_set = metric_set(accuracy))
model_table %>%
modeltime_calibrate(testing(splits)) %>%
modeltime_accuracy( metric_set = metric_set(accuracy(quiet = F)))
library(tidyverse) #install.packages("tidyverse")
# 'https://datos.covid-19.conacyt.mx/Downloads/Files/Casos_Diarios_Estado_Nacional_Confirmados_20211009.csv'
# 'https://datos.covid-19.conacyt.mx/Downloads/Files/Casos_Diarios_Estado_Nacional_Confirmados_20211006.csv'
#------------- añadir fecha actual automaticamente
# obtenemos la fecha del dia anterior
fecha_yesterday <- Sys.Date()-1; fecha_yesterday
# convertimos ese objeto a uno de tipo "character"
fecha_yesterday <- as.character(fecha_yesterday); fecha_yesterday
# eliminamos los "-", para obtener la fecha corrida
fecha_yesterday <- gsub("-", "",fecha_yesterday); fecha_yesterday
# la siguiente url contiene el archivo CSV del 06 de octubre de 2021
# con la información correspondiente , la cual va a ser modificada
url_covid <- 'https://datos.covid-19.conacyt.mx/Downloads/Files/Casos_Diarios_Estado_Nacional_Defunciones_20211006.csv'
# igualemnte con la función gsub, reemplazamos ahora
# en la url los ultimos valores por la fecha actuañ
url_covid <- gsub("20211006", fecha_yesterday, url_covid); url_covid
data <- read.csv(url_covid, header = TRUE)
data <- data %>%
select(-cve_ent, -poblacion) %>%
pivot_longer(!nombre, names_to = "fecha", values_to = "defunciones") %>%
pivot_wider(names_from = nombre, values_from = defunciones) %>%
mutate(fecha = gsub("X", "", fecha)) %>%
mutate(fecha = as.Date(fecha, "%d.%m.%Y")) %>%
select(c(2:33),1)
if (any(is.na(data)) == TRUE) {data = tidyr::drop_na(data)}  # TRUE = hay al menos un valor NA
library(tidymodels) #install.packages("tidymodels")
library(modeltime)  #install.packages("modeltime")
library(timetk)     #install.packages("timetk")
library(lubridate)  #install.packages("lubridate")
library(tidyverse)  #install.packages("tidyverse")
library(lubridate)  #install.packages("lubridate")
ts.agu <- ts(data[1],
start = c(2020, as.numeric(format(data$fecha[1], "%j"))),
frequency = 365)
ts.agu.tbl <- data %>%
select(33, 1) %>%  # select(fecha, AGUASCALIENTES)
set_names(c("date", "confirmados"))
head(ts.agu.tbl)
ts.agu.tbl %>%
plot_time_series(date, confirmados, .interactive = F)
splits <- ts.agu.tbl %>%
time_series_split(assess = "3 months", cumulative = TRUE)
splits %>%
tk_time_series_cv_plan() %>%
plot_time_series_cv_plan(date, confirmados, .interactive = FALSE)
model_fit_arima <- arima_reg() %>%
set_engine("auto_arima") %>%
fit(confirmados ~ date, training(splits))
model_fit_arima
model_fit_prophet <- prophet_reg(seasonality_daily = TRUE) %>%
set_engine("prophet") %>%
fit(confirmados ~ date, training(splits))
model_fit_prophet
recipe_spec <- recipe(confirmados ~ date, training(splits)) %>%
step_timeseries_signature(date) %>%
step_rm(contains("am.pm"), contains("hour"), contains("minute"),
contains("second"), contains("xts")) %>%
step_fourier(date, period = 365, K = 5) %>%
step_dummy(all_nominal())
recipe_spec %>% prep() %>% juice()
model_spec_glmnet <- linear_reg(penalty = 0.01, mixture = 0.5) %>%
set_engine("glmnet")
workflow_fit_glmnet <- workflow() %>%
add_model(model_spec_glmnet) %>%
add_recipe(recipe_spec %>% step_rm(date)) %>%
fit(training(splits))
model_spec_rf <- rand_forest(trees = 500, min_n = 50) %>%
set_engine("randomForest")
workflow_fit_rf <- workflow() %>%
add_model(model_spec_rf) %>%
add_recipe(recipe_spec %>% step_rm(date)) %>%
fit(training(splits))
model_spec_prophet_boost <- prophet_boost(seasonality_yearly = TRUE) %>%
set_engine("prophet_xgboost")
workflow_fit_prophet_boost <- workflow() %>%
add_model(model_spec_prophet_boost) %>%
add_recipe(recipe_spec) %>%
fit(training(splits))
workflow_fit_prophet_boost
model_fit_nnetar <- nnetar_reg() %>%
set_engine("nnetar") %>%
fit(confirmados ~ date, training(splits))
model_fit_nnetar
model_table <- modeltime_table(
model_fit_arima,
model_fit_prophet,
workflow_fit_glmnet,
workflow_fit_rf,
workflow_fit_prophet_boost,
model_fit_nnetar
)
model_table
calibration_table <- model_table %>%
modeltime_calibrate(testing(splits))
calibration_table
calibration_table %>%
modeltime_forecast(actual_data = ts.agu.tbl) %>%
plot_modeltime_forecast(.interactive = T)
calibration_table %>%
modeltime_accuracy() %>%
table_modeltime_accuracy(.interactive = F)
calibration_table %>%
# Remove ARIMA model with low accuracy
# filter(.model_id != 4) %>%
# Refit and Forecast Forward
modeltime_refit(ts.agu.tbl) %>%
modeltime_forecast(h = "1 month", actual_data = ts.agu.tbl) %>%
plot_modeltime_forecast(.interactive = T)
calibration_table %>%
modeltime_residuals_test()
calibration_table %>%
modeltime_residuals() %>%
plot_modeltime_residuals()
calibration_table %>%
modeltime_residuals_test()
calibration_table %>%
plot_acf_diagnostics()
calibration_table %>%
modeltime_residuals() %>%
plot_acf_diagnostics()
calibration_table
calibration_table %>%
group_by(.model_id) %>%
plot_seasonal_diagnostics()
calibration_table %>%
modeltime_forecast(actual_data = ts.agu.tbl)
calibration_table %>%
modeltime_forecast(actual_data = ts.agu.tbl) %>%
plot_seasonal_diagnostics()
calibration_table %>%
group_by(.model_id)
calibration_table %>%
group_by(.model_id) %>%
modeltime_forecast(actual_data = ts.agu.tbl) %>%
plot_seasonal_diagnostics()
ts.agu.tbl %>%
plot_acf_diagnostics()
ts.agu.tbl
ts.agu.tbl %>%
plot_acf_diagnostics(        date, confirmados,               # ACF & PACF
.lags = "7 days",          # 7-Days of hourly lags
.interactive = FALSE)
ts.agu.tbl %>%
plot_acf_diagnostics(        date, confirmados,               # ACF & PACF
.lags = "30 days",          # 7-Days of hourly lags
.interactive = FALSE)
ts.agu.tbl %>%
plot_acf_diagnostics(date, confirmados,               # ACF & PACF
#.lags = "30 days",          # 7-Days of hourly lags
.interactive = FALSE)
ts.agu.tbl %>%
plot_acf_diagnostics(date, confirmados,               # ACF & PACF
#.lags = "30 days",          # 7-Days of hourly lags
.interactive = FALSE)
ts.agu.tbl %>%
plot_seasonal_diagnostics()
ts.agu.tbl %>%
plot_seasonal_diagnostics(date, confirmados)
ts.agu.tbl %>%
plot_acf_diagnostics(date, confirmados,               # ACF & PACF
.lags = "30 days",          # 7-Days of hourly lags
.interactive = FALSE)
ts.agu.tbl %>%
plot_acf_diagnostics(date, confirmados,               # ACF & PACF
#.lags = "30 days",          # 7-Days of hourly lags
.interactive = FALSE)
ts.agu.tbl %>%
plot_acf_diagnostics(date, confirmados,               # ACF & PACF
.lags = "300 days",          # 7-Days of hourly lags
.interactive = FALSE)
ts.agu.tbl %>%
plot_acf_diagnostics(date, confirmados,               # ACF & PACF
.lags = "30 days",          # 7-Days of hourly lags
.interactive = FALSE)
ts.agu.tbl %>%
plot_acf_diagnostics(date, confirmados,               # ACF & PACF
#.lags = "30 days",          # 7-Days of hourly lags
.interactive = FALSE)
ts.agu.tbl %>%
plot_seasonal_diagnostics(date, confirmados)
ts.agu.tbl %>%
plot_acf_diagnostics(date, confirmados,               # ACF & PACF
.lags = "10 days",          # 7-Days of hourly lags
.interactive = FALSE)
ts.agu.tbl %>%
plot_acf_diagnostics(date, confirmados,               # ACF & PACF
.lags = "50 days",          # 7-Days of hourly lags
.interactive = FALSE)
